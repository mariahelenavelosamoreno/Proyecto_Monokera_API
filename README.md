# üõ∞Ô∏è Proyecto ETL para Spaceflight News API

## üìå Descripci√≥n del Proyecto

Este proyecto implementa un pipeline **ETL** para extraer datos de la API de **Spaceflight News** (art√≠culos y blogs), transformarlos y cargarlos en archivos CSV. El sistema est√° construido con **Python** y **Apache Airflow**, permitiendo ejecuciones programadas y monitoreo del flujo de datos.

---

## üéØ Objetivos

- Extraer hasta **1000 registros** de los endpoints `/articles` y `/blogs`  
- Transformar los campos de fecha al formato `YYYY/MM/DD`  
- Generar archivos **CSV con separador `;`**  
- Implementar validaciones de calidad de datos  
- Crear un pipeline **automatizado y reproducible**

---

## üèóÔ∏è Arquitectura

![Arquitectura del Proyecto](https://lucid.app/lucidchart/988d7156-d739-4fa9-be01-a13a76fd7a4e/view)

### Flujo principal:

1. **Extracci√≥n:** Consumo de API ‚Üí Datos RAW  
2. **Transformaci√≥n:** Limpieza y formateo ‚Üí Datos STAGING  
3. **Validaci√≥n:** Verificaci√≥n de calidad  
4. **Carga:** Generaci√≥n de archivos finales

### Componentes:

- **Airflow** (Orquestaci√≥n)  
- **Python** (Procesamiento)  
- **Great Expectations** (Validaci√≥n)  
- **Docker** (Entorno de ejecuci√≥n)

---

## üõ†Ô∏è Configuraci√≥n

### Requisitos previos

- Docker y Docker Compose  
- Python 3.10+  
- WSL2 (para usuarios Windows)

### Instalaci√≥n

Clona el repositorio:

```bash
git clone https://github.com/tu-usuario/spaceflight-etl.git
cd spaceflight-etl
