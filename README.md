# ğŸ›°ï¸ Proyecto ETL para Spaceflight News API

## ğŸ“Œ DescripciÃ³n del Proyecto

Este proyecto implementa un pipeline **ETL** para extraer datos de la API de **Spaceflight News** (artÃ­culos y blogs), transformarlos y cargarlos en archivos CSV. El sistema estÃ¡ construido con **Python** y **Apache Airflow**, permitiendo ejecuciones programadas y monitoreo del flujo de datos.

---

## ğŸ¯ Objetivos

- Extraer hasta **1000 registros** de los endpoints `/articles` y `/blogs`  
- Transformar los campos de fecha al formato `YYYY/MM/DD`  
- Generar archivos **CSV con separador `;`**  
- Implementar validaciones de calidad de datos  
- Crear un pipeline **automatizado y reproducible**

---

## ğŸ—ï¸ Arquitectura

![Arquitectura del Proyecto](https://docs/architecture.png)

### Flujo principal:

1. **ExtracciÃ³n:** Consumo de API â†’ Datos RAW  
2. **TransformaciÃ³n:** Limpieza y formateo â†’ Datos STAGING  
3. **ValidaciÃ³n:** VerificaciÃ³n de calidad  
4. **Carga:** GeneraciÃ³n de archivos finales

### Componentes:

- **Airflow** (OrquestaciÃ³n)  
- **Python** (Procesamiento)  
- **Great Expectations** (ValidaciÃ³n)  
- **Docker** (Entorno de ejecuciÃ³n)

---

## ğŸ› ï¸ ConfiguraciÃ³n

### Requisitos previos

- Docker y Docker Compose  
- Python 3.10+  
- WSL2 (para usuarios Windows)

### InstalaciÃ³n

Clona el repositorio:

```bash
git clone https://github.com/tu-usuario/spaceflight-etl.git
cd spaceflight-etl
