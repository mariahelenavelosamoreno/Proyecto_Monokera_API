{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "18fa78bd",
   "metadata": {},
   "source": [
    "Liberias "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d776dbd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import pandas as pd\n",
    "import os\n",
    "import json\n",
    "from pandas import json_normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "927de1c0",
   "metadata": {},
   "source": [
    "Configuración inicial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "584bfae5",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE_URL = \"https://api.spaceflightnewsapi.net/v4/blogs/\"\n",
    "LIMIT = 500\n",
    "STATE_FILE = \"state.json\"\n",
    "MAX_ARTICLES = 1000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d096c30",
   "metadata": {},
   "source": [
    "Cargar estado desde archivo (offset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "587874e0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Cargando artículos desde offset: 0\n"
     ]
    }
   ],
   "source": [
    "def load_state():\n",
    "    if os.path.exists(STATE_FILE):\n",
    "        with open(STATE_FILE, \"r\") as f:\n",
    "            return json.load(f)\n",
    "    return {\n",
    "        \"offset\": 0\n",
    "    }\n",
    "\n",
    "state = load_state()\n",
    "current_offset = state[\"offset\"]\n",
    "print(f\"\\n Cargando artículos desde offset: {current_offset}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ea14aa5",
   "metadata": {},
   "source": [
    "Obtener la data de acuerdo a los parametros que se requieren y el ultimo offset si es que se ejecuta nuevamente el workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "963f3e6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fetch_articles(offset):\n",
    "    params = {\n",
    "        \"limit\": LIMIT,\n",
    "        \"offset\": offset,\n",
    "        \"ordering\": \"updated_at\"\n",
    "    }\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")\n",
    "    return response.json()[\"results\"]\n",
    "\n",
    "data = []\n",
    "if current_offset == 0:\n",
    "    stop = False\n",
    "    while stop == False:\n",
    "        data_i = fetch_articles(current_offset)\n",
    "        data.extend(data_i)\n",
    "        if len(data_i) < LIMIT:\n",
    "            stop = True\n",
    "        current_offset += LIMIT\n",
    "        print(f\" Cargando artículos desde offset: {current_offset}\")\n",
    "    if not data:\n",
    "        print(\" No hay más artículos disponibles.\")\n",
    "        exit()\n",
    "\n",
    "data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "754f5ca4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28677"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0baa7d94",
   "metadata": {},
   "source": [
    "1000 datos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30f912be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cargando artículos desde offset: 500\n",
      " Cargando artículos desde offset: 1000\n",
      "Total de artículos cargados: 1000\n"
     ]
    }
   ],
   "source": [
    "def fetch_articles(offset):\n",
    "    params = {\n",
    "        \"limit\": LIMIT,\n",
    "        \"offset\": offset,\n",
    "        \"ordering\": \"updated_at\"\n",
    "    }\n",
    "    response = requests.get(BASE_URL, params=params)\n",
    "    if response.status_code != 200:\n",
    "        raise Exception(f\"Error {response.status_code}: {response.text}\")\n",
    "    return response.json()[\"results\"]\n",
    "\n",
    "data = []\n",
    "stop = False\n",
    "\n",
    "while not stop:\n",
    "    data_i = fetch_articles(current_offset)\n",
    "    if not data_i:\n",
    "        stop = True\n",
    "        break\n",
    "    \n",
    "    data.extend(data_i)\n",
    "    current_offset += LIMIT\n",
    "\n",
    "    print(f\" Cargando artículos desde offset: {current_offset}\")\n",
    "    \n",
    "    #  Detener si ya se alcanzaron 1000 registros\n",
    "    if len(data) >= MAX_ARTICLES:\n",
    "        stop = True\n",
    "\n",
    "#  Cortar a exactamente 1000 si por alguna razón se pasaron\n",
    "data = data[:MAX_ARTICLES]\n",
    "\n",
    "print(f\"Total de artículos cargados: {len(data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3287d6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mil_df = json_normalize(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "51a0d35a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 12 columns):\n",
      " #   Column        Non-Null Count  Dtype \n",
      "---  ------        --------------  ----- \n",
      " 0   id            1000 non-null   int64 \n",
      " 1   title         1000 non-null   object\n",
      " 2   authors       1000 non-null   object\n",
      " 3   url           1000 non-null   object\n",
      " 4   image_url     1000 non-null   object\n",
      " 5   news_site     1000 non-null   object\n",
      " 6   summary       1000 non-null   object\n",
      " 7   published_at  1000 non-null   object\n",
      " 8   updated_at    1000 non-null   object\n",
      " 9   featured      1000 non-null   bool  \n",
      " 10  launches      1000 non-null   object\n",
      " 11  events        1000 non-null   object\n",
      "dtypes: bool(1), int64(1), object(10)\n",
      "memory usage: 87.0+ KB\n"
     ]
    }
   ],
   "source": [
    "mil_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5211d987",
   "metadata": {},
   "source": [
    "Convertir de json a dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "fe06da83",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df = json_normalize(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faf01ee6",
   "metadata": {},
   "source": [
    "ver data RAW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1342becb",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7b38e71",
   "metadata": {},
   "source": [
    "Descripción de la data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2574a114",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.describe(include='all')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4830fbc8",
   "metadata": {},
   "source": [
    "Ver toda la información de la data para poder identificar la data que tenemos, de que tipo  y el conteo del numero de filas obtenidas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0392b77e",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a8b653c",
   "metadata": {},
   "source": [
    "Nombre de Columnas "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "daab5e7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columnas RAW:\n",
      "['id', 'title', 'authors', 'url', 'image_url', 'news_site', 'summary', 'published_at', 'updated_at', 'featured', 'launches', 'events']\n"
     ]
    }
   ],
   "source": [
    "print(\"Columnas RAW:\")\n",
    "print(raw_df.columns.tolist())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd206712",
   "metadata": {},
   "source": [
    "Crear la carpeta 'raw' si no existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "d0d4be9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"raw\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c02e2d",
   "metadata": {},
   "source": [
    "Almacenamiento local de la primera extración raw"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "71ad0366",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo RAW guardado en: raw/2025-07-13_15-53-54_articulos_espaciales_test.csv\n"
     ]
    }
   ],
   "source": [
    "datetime = pd.Timestamp.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "output_file = f\"raw/{datetime}_articulos_espaciales_test.csv\"\n",
    "raw_df.to_csv(output_file, sep=';', index=False)\n",
    "print(f\"\\nArchivo RAW guardado en: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "510537f3",
   "metadata": {},
   "source": [
    "Leer el archivo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "388b764e",
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file = f\"raw/{datetime}_articulos_espaciales_test.csv\"\n",
    "df = pd.read_csv(output_file, sep=';')\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6447c95",
   "metadata": {},
   "source": [
    "LIMPIEZA"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7cc8175",
   "metadata": {},
   "source": [
    "Verificar si hay duplicados, si es FALSE es porque no hay "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f3a9461d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.duplicated(subset=['id']).all()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7e641c4",
   "metadata": {},
   "source": [
    "Borrar duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "723d7e6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(subset=['id'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e0a6055",
   "metadata": {},
   "source": [
    "Organizar la data para que aparezca del primer dato insertado en adelante"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5479e37a",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.sort_values(by='updated_at', ascending=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece49081",
   "metadata": {},
   "source": [
    "Formateando y normalizando la data y creación de dos columnas las cuales guardan la data con la hora exacta para no perder data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88e8c5c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['published_datetime'] = pd.to_datetime(df['published_at'])\n",
    "df['published_at'] = pd.to_datetime(df['published_at']).dt.date\n",
    "df['updated_datetime'] = pd.to_datetime(df['updated_at'])\n",
    "df['updated_at'] = pd.to_datetime(df['updated_at']).dt.date\n",
    "df['id'] = df['id'].astype(int)\n",
    "#df['featured'] = df['featured'].astype(bool) ya viene booleano\n",
    "\n",
    "# Limpiar columnas de texto\n",
    "text_columns = ['title', 'authors', 'url', 'image_url', 'news_site', 'summary']\n",
    "for col in text_columns:\n",
    "    df[col] = df[col].astype(str).str.strip()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a53fbf1",
   "metadata": {},
   "source": [
    "verificar cambios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4271b16",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c105b077",
   "metadata": {},
   "source": [
    "Crear la carpeta de Staging si no existe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "206f1745",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.makedirs(\"staging\", exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a4acf5dd",
   "metadata": {},
   "source": [
    "Guardar la data en el cvs de staging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a0937491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archivo staging guardado en: staging/2025-07-13_15-54-20_articulos_espaciales_test.csv\n"
     ]
    }
   ],
   "source": [
    "datetime = pd.Timestamp.now().strftime('%Y-%m-%d_%H-%M-%S')\n",
    "output_file = f\"staging/{datetime}_articulos_espaciales_test.csv\"\n",
    "df.to_csv(output_file, sep=';', index=False)\n",
    "print(f\"Archivo staging guardado en: {output_file}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb44279",
   "metadata": {},
   "source": [
    "Actualizar el JSON con el ultimo offset agregado "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "03b2e0b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_state(offset):\n",
    "    with open(STATE_FILE, \"w\") as f:\n",
    "        json.dump({\"offset\": offset}, f)\n",
    "\n",
    "new_offset = current_offset + LIMIT\n",
    "save_state(new_offset)\n",
    "print(f\"Nuevo offset guardado: {new_offset}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "testenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
